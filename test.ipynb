{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1a949904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Logic regarding sequential bootstrapping from chapter 4.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numba import jit, prange\n",
    "\n",
    "\n",
    "def get_ind_matrix(samples_info_sets, price_bars):\n",
    "    \"\"\"\n",
    "    Advances in Financial Machine Learning, Snippet 4.3, page 65.\n",
    "\n",
    "    Build an Indicator Matrix\n",
    "\n",
    "    Get indicator matrix. The book implementation uses bar_index as input, however there is no explanation\n",
    "    how to form it. We decided that using triple_barrier_events and price bars by analogy with concurrency\n",
    "    is the best option.\n",
    "\n",
    "    :param samples_info_sets: (pd.Series): Triple barrier events(t1) from labeling.get_events\n",
    "    :param price_bars: (pd.DataFrame): Price bars which were used to form triple barrier events\n",
    "    :return: (np.array) Indicator binary matrix indicating what (price) bars influence the label for each observation\n",
    "    \"\"\"\n",
    "    if bool(samples_info_sets.isnull().values.any()) is True or bool(\n",
    "            samples_info_sets.index.isnull().any()) is True:\n",
    "        raise ValueError('NaN values in triple_barrier_events, delete nans')\n",
    "\n",
    "    triple_barrier_events = pd.DataFrame(samples_info_sets)  # Convert Series to DataFrame\n",
    "\n",
    "    # Take only period covered in triple_barrier_events\n",
    "    trimmed_price_bars_index = price_bars[(price_bars.index >= triple_barrier_events.index.min()) &\n",
    "                                          (price_bars.index <= triple_barrier_events.t1.max())].index\n",
    "\n",
    "    label_endtime = triple_barrier_events.t1\n",
    "    bar_index = list(triple_barrier_events.index)  # Generate index for indicator matrix from t1 and index\n",
    "    bar_index.extend(triple_barrier_events.t1)\n",
    "    bar_index.extend(trimmed_price_bars_index)  # Add price bars index\n",
    "    bar_index = sorted(list(set(bar_index)))  # Drop duplicates and sort\n",
    "\n",
    "    # Get sorted timestamps with index in sorted array\n",
    "    sorted_timestamps = dict(zip(bar_index, range(len(bar_index))))\n",
    "\n",
    "    tokenized_endtimes = np.column_stack((label_endtime.index.map(sorted_timestamps), label_endtime.map(\n",
    "        sorted_timestamps).values))  # Create array of arrays: [label_index_position, label_endtime_position]\n",
    "\n",
    "    ind_mat = np.zeros((len(bar_index), len(label_endtime)))  # Init indicator matrix\n",
    "    for sample_num, label_array in enumerate(tokenized_endtimes):\n",
    "        label_index = label_array[0]\n",
    "        label_endtime = label_array[1]\n",
    "        ones_array = np.ones(\n",
    "            (1, label_endtime - label_index + 1))  # Ones array which corresponds to number of 1 to insert\n",
    "        ind_mat[label_index:label_endtime + 1, sample_num] = ones_array\n",
    "    return ind_mat\n",
    "\n",
    "\n",
    "def get_ind_mat_average_uniqueness(ind_mat):\n",
    "    \"\"\"\n",
    "    Advances in Financial Machine Learning, Snippet 4.4. page 65.\n",
    "\n",
    "    Compute Average Uniqueness\n",
    "\n",
    "    Average uniqueness from indicator matrix\n",
    "\n",
    "    :param ind_mat: (np.matrix) Indicator binary matrix\n",
    "    :return: (float) Average uniqueness\n",
    "    \"\"\"\n",
    "    ind_mat = np.array(ind_mat, dtype=np.float64)\n",
    "    concurrency = ind_mat.sum(axis=1)\n",
    "    uniqueness = np.divide(ind_mat.T, concurrency, out=np.zeros_like(ind_mat.T), where=concurrency != 0)\n",
    "\n",
    "    avg_uniqueness = uniqueness[uniqueness > 0].mean()\n",
    "\n",
    "    return avg_uniqueness\n",
    "\n",
    "\n",
    "def get_ind_mat_label_uniqueness(ind_mat):\n",
    "    \"\"\"\n",
    "    Advances in Financial Machine Learning, An adaption of Snippet 4.4. page 65.\n",
    "\n",
    "    Returns the indicator matrix element uniqueness.\n",
    "\n",
    "    :param ind_mat: (np.matrix) Indicator binary matrix\n",
    "    :return: (np.matrix) Element uniqueness\n",
    "    \"\"\"\n",
    "    ind_mat = np.array(ind_mat, dtype=np.float64)\n",
    "    concurrency = ind_mat.sum(axis=1)\n",
    "    uniqueness = np.divide(ind_mat.T, concurrency, out=np.zeros_like(ind_mat.T), where=concurrency != 0)\n",
    "    return uniqueness\n",
    "\n",
    "\n",
    "@jit(parallel=True, nopython=True)\n",
    "def _bootstrap_loop_run(ind_mat, prev_concurrency):  # pragma: no cover\n",
    "    \"\"\"\n",
    "    Part of Sequential Bootstrapping for-loop. Using previously accumulated concurrency array, loops through all samples\n",
    "    and generates averages uniqueness array of label based on previously accumulated concurrency\n",
    "\n",
    "    :param ind_mat (np.array): Indicator matrix from get_ind_matrix function\n",
    "    :param prev_concurrency (np.array): Accumulated concurrency from previous iterations of sequential bootstrapping\n",
    "    :return: (np.array): Label average uniqueness based on prev_concurrency\n",
    "    \"\"\"\n",
    "    avg_unique = np.zeros(ind_mat.shape[1])  # Array of label uniqueness\n",
    "\n",
    "    for i in prange(ind_mat.shape[1]):  # pylint: disable=not-an-iterable\n",
    "        prev_average_uniqueness = 0\n",
    "        number_of_elements = 0\n",
    "        reduced_mat = ind_mat[:, i]\n",
    "        for j in range(len(reduced_mat)):  # pylint: disable=consider-using-enumerate\n",
    "            if reduced_mat[j] > 0:\n",
    "                new_el = reduced_mat[j] / (reduced_mat[j] + prev_concurrency[j])\n",
    "                average_uniqueness = (prev_average_uniqueness * number_of_elements + new_el) / (number_of_elements + 1)\n",
    "                number_of_elements += 1\n",
    "                prev_average_uniqueness = average_uniqueness\n",
    "        avg_unique[i] = average_uniqueness\n",
    "    return avg_unique\n",
    "\n",
    "\n",
    "def seq_bootstrap(ind_mat, sample_length=None, warmup_samples=None, compare=False, verbose=False,\n",
    "                  random_state=np.random.RandomState()):\n",
    "    \"\"\"\n",
    "    Advances in Financial Machine Learning, Snippet 4.5, Snippet 4.6, page 65.\n",
    "\n",
    "    Return Sample from Sequential Bootstrap\n",
    "\n",
    "    Generate a sample via sequential bootstrap.\n",
    "    Note: Moved from pd.DataFrame to np.matrix for performance increase\n",
    "\n",
    "    :param ind_mat: (pd.DataFrame) Indicator matrix from triple barrier events\n",
    "    :param sample_length: (int) Length of bootstrapped sample\n",
    "    :param warmup_samples: (list) List of previously drawn samples\n",
    "    :param compare: (boolean) Flag to print standard bootstrap uniqueness vs sequential bootstrap uniqueness\n",
    "    :param verbose: (boolean) Flag to print updated probabilities on each step\n",
    "    :param random_state: (np.random.RandomState) Random state\n",
    "    :return: (array) Bootstrapped samples indexes\n",
    "    \"\"\"\n",
    "\n",
    "    if sample_length is None:\n",
    "        sample_length = ind_mat.shape[1]\n",
    "\n",
    "    if warmup_samples is None:\n",
    "        warmup_samples = []\n",
    "\n",
    "    phi = []  # Bootstrapped samples\n",
    "    prev_concurrency = np.zeros(ind_mat.shape[0])  # Init with zeros (phi is empty)\n",
    "    while len(phi) < sample_length:\n",
    "        avg_unique = _bootstrap_loop_run(ind_mat, prev_concurrency)\n",
    "        #avg_unique[phi] = 0\n",
    "        prob = avg_unique / sum(avg_unique)  # Draw prob\n",
    "        try:\n",
    "            choice = warmup_samples.pop(0)  # It would get samples from warmup until it is empty\n",
    "            # If it is empty from the beginning it would get samples based on prob from the first iteration\n",
    "        except IndexError:\n",
    "            choice = random_state.choice(range(ind_mat.shape[1]), p=prob)\n",
    "        choice= 0\n",
    "        phi += [choice]\n",
    "        prev_concurrency += ind_mat[:, choice]  # Add recorded label array from ind_mat\n",
    "        if verbose is True:\n",
    "            print(prob)\n",
    "\n",
    "    if compare is True:\n",
    "        standard_indx = np.random.choice(ind_mat.shape[1], size=sample_length)\n",
    "        standard_unq = get_ind_mat_average_uniqueness(ind_mat[:, standard_indx])\n",
    "        sequential_unq = get_ind_mat_average_uniqueness(ind_mat[:, phi])\n",
    "        print('Standard uniqueness: {}\\nSequential uniqueness: {}'.format(standard_unq, sequential_unq))\n",
    "\n",
    "    return phi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09119625",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_bars = pd.Series(index=pd.date_range(start=\"1/1/2018\", end='1/8/2018', freq='H'), dtype='float64')\n",
    "samples_info_sets = pd.DataFrame(index=price_bars.index[[1, 2, 5, 7, 10, 11, 12, 20,]])\n",
    "samples_info_sets['t1'] =samples_info_sets.index + pd.Timedelta('2H')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2a3038e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_mat = get_ind_matrix(samples_info_sets.t1, price_bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "108cd028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "43aa5aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.125 0.125 0.125 0.125 0.125 0.125 0.125 0.125]\n",
      "[0.06976744 0.09302326 0.13953488 0.13953488 0.13953488 0.13953488\n",
      " 0.13953488 0.13953488]\n",
      "[0.0483871  0.08064516 0.14516129 0.14516129 0.14516129 0.14516129\n",
      " 0.14516129 0.14516129]\n",
      "[0.03703704 0.07407407 0.14814815 0.14814815 0.14814815 0.14814815\n",
      " 0.14814815 0.14814815]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_bootstrap(ind_mat, compare=False, verbose=True, warmup_samples=None, sample_length=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04aa432d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "067e8445",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'POLARS_MAX_THREADS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOLARS_MAX_THREADS=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOLARS_MAX_THREADS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "File \u001b[0;32m/usr/lib/python3.8/os.py:675\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    672\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'POLARS_MAX_THREADS'"
     ]
    }
   ],
   "source": [
    "print('POLARS_MAX_THREADS={}'.format(os.environ['POLARS_MAX_THREADS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "30fa6c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6f0ed151",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export POLARS_MAX_THREADS=8\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "abd64dfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'POLARS_MAX_THREADS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPOLARS_MAX_THREADS=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOLARS_MAX_THREADS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m))\n",
      "File \u001b[0;32m/usr/lib/python3.8/os.py:675\u001b[0m, in \u001b[0;36m_Environ.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    672\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencodekey(key)]\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[1;32m    674\u001b[0m     \u001b[38;5;66;03m# raise KeyError with the original key value\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecodevalue(value)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'POLARS_MAX_THREADS'"
     ]
    }
   ],
   "source": [
    "print('POLARS_MAX_THREADS={}'.format(os.environ['POLARS_MAX_THREADS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5877975e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
